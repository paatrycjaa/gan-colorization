{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colorization of panchromatic space images with Generative Adversarial Network\n",
    "\n",
    "Author: Patrycja Cieplicka\n",
    "\n",
    "Date: 12 Jan 2020\n",
    "\n",
    "Implementation of class Generative Adversarial Network for second model colorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.full.packages import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "set_random_seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN_two():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.g_input_shape = (128,128,1)\n",
    "        self.d_input_shape = (128,128,3)\n",
    "        \n",
    "        #Compiling generator\n",
    "        self.generator = self.build_generator()\n",
    "        opt = Adam(lr = 0.0001)\n",
    "        self.generator.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "        print('Generator Summary...')\n",
    "        print(self.generator.summary())\n",
    "        \n",
    "        #Compiling discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        opt = Adam(lr = 0.0001)\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "        print('Discriminator Summary...')\n",
    "        print(self.discriminator.summary())\n",
    "\n",
    "        #Initialize GAN\n",
    "        gan_input = Input(shape=self.g_input_shape)\n",
    "        img_color = self.generator(gan_input)\n",
    "        self.discriminator.trainable = False\n",
    "        real_or_fake = self.discriminator([gan_input, img_color])\n",
    "        self.gan = Model(inputs = gan_input, outputs = real_or_fake)\n",
    "        \n",
    "        #Compiling GAN\n",
    "        opt = Adam(lr = 0.001)\n",
    "        self.gan.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "        print('\\n')\n",
    "        print('GAN summary...')\n",
    "        print(self.gan.summary())\n",
    "\n",
    "    def build_generator(self):\n",
    "        #Generator model\n",
    "        \n",
    "        g_input = Input(shape=self.g_input_shape)\n",
    "        \n",
    "        #128 x 128\n",
    "        conv1 = Conv2D(64, (3, 3), padding='same', strides=2)(g_input)\n",
    "        conv1 = BatchNormalization()(conv1)\n",
    "        conv1 = Activation('relu')(conv1)\n",
    "\n",
    "        conv2 = Conv2D(128, (3, 3), padding='same', strides=1)(conv1)\n",
    "        conv2 = BatchNormalization()(conv2)\n",
    "        conv2 = Activation('relu')(conv2)\n",
    "\n",
    "        #64 x 64\n",
    "        conv3 = Conv2D(128, (3, 3), padding='same', strides=2)(conv2)\n",
    "        conv3 = BatchNormalization()(conv3)\n",
    "        conv3 = Activation('relu')(conv3)\n",
    "\n",
    "        conv4 = Conv2D(256, (3, 3), padding='same', strides=1)(conv3)\n",
    "        conv4 = BatchNormalization()(conv4)\n",
    "        conv4 = Activation('relu')(conv4)\n",
    "        \n",
    "         #32 x 32\n",
    "        conv5 = Conv2D(256, (3, 3), padding='same', strides=2)(conv4)\n",
    "        conv5 = BatchNormalization()(conv5)\n",
    "        conv5 = Activation('relu')(conv5)\n",
    "\n",
    "        conv6 = Conv2D(512, (3, 3), padding='same', strides=1)(conv5)\n",
    "        conv6 = BatchNormalization()(conv5)\n",
    "        conv6 = Activation('relu')(conv5)\n",
    "\n",
    "        #16 x16\n",
    "        conv7 = Conv2D(512, (3, 3), padding='same', strides=2)(conv6)\n",
    "        conv7 = BatchNormalization()(conv7)\n",
    "        conv7 = Activation('relu')(conv7)\n",
    "        \n",
    "        #32 x 32\n",
    "        conv8 = UpSampling2D(size=(2, 2))(conv7)\n",
    "        conv8 = Conv2D(512, (3, 3), padding='same')(conv8)\n",
    "        conv8 = BatchNormalization()(conv8)\n",
    "        conv8 = Activation('relu')(conv8)\n",
    "        conv8 = Concatenate(axis=-1)([conv8,conv6])\n",
    "\n",
    "        conv9 = Conv2D(512, (3, 3), padding='same')(conv8)\n",
    "        conv9 = BatchNormalization()(conv9)\n",
    "        conv9 = Activation('relu')(conv9)\n",
    "\n",
    "        #64 x 64\n",
    "        conv10 = UpSampling2D(size=(2, 2))(conv9)\n",
    "        conv10 = Conv2D(256, (3, 3), padding='same')(conv10)\n",
    "        conv10 = BatchNormalization()(conv10)\n",
    "        conv10 = Activation('relu')(conv10)\n",
    "        conv10 = Concatenate(axis=-1)([conv10,conv4])\n",
    "\n",
    "        conv11 = Conv2D(256, (3, 3), padding='same')(conv10)\n",
    "        conv11 = BatchNormalization()(conv11)\n",
    "        conv11 = Activation('relu')(conv11)\n",
    "\n",
    "        #128 x 128\n",
    "        conv12 = UpSampling2D(size=(2, 2))(conv11)\n",
    "        conv12 = Conv2D(128, (3,3), padding='same')(conv12)\n",
    "        conv12 = BatchNormalization()(conv12)\n",
    "        conv12 = Activation('relu')(conv12)\n",
    "        conv12 = Concatenate(axis=-1)([conv12,conv2])\n",
    "\n",
    "        conv13 = Conv2D(128, (3, 3), padding='same')(conv12)\n",
    "        conv13 = BatchNormalization()(conv13)\n",
    "        conv13 = Activation('relu')(conv13)\n",
    "        \n",
    "        #256 x 256\n",
    "        conv14 = UpSampling2D(size=(2, 2))(conv13)\n",
    "        conv14 = Conv2D(64, (3,3), padding='same')(conv14)\n",
    "        conv14 = BatchNormalization()(conv14)\n",
    "        conv14 = Activation('relu')(conv14)\n",
    "\n",
    "        conv15 = Conv2D(3, (3, 3), padding='same')(conv14)\n",
    "        conv15 = Activation('tanh')(conv15)\n",
    "\n",
    "        model = Model(inputs=g_input,outputs=conv15)\n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        #Dicriminator model\n",
    "        \n",
    "        d_input_lab = Input(shape=self.d_input_shape)\n",
    "        d_input_l = Input(shape=self.g_input_shape)\n",
    "        \n",
    "        #128 x128\n",
    "        disc_conv1 = concatenate([d_input_l, d_input_lab], axis=3) \n",
    "        disc_conv1 = Conv2D(32, (3, 3), padding='same', strides=1)(disc_conv1)\n",
    "        disc_conv1 = BatchNormalization()(disc_conv1)\n",
    "        disc_conv1 = LeakyReLU()(disc_conv1)\n",
    "\n",
    "        disc_conv1 = Conv2D(64, (3, 3), padding='same', strides=2)(disc_conv1)\n",
    "        disc_conv1 = BatchNormalization()(disc_conv1)\n",
    "        disc_conv1 = LeakyReLU()(disc_conv1)\n",
    "\n",
    "        #64x64\n",
    "        disc_conv1 = Conv2D(128, (3, 3), padding='same', strides=2)(disc_conv1)\n",
    "        disc_conv1 = BatchNormalization()(disc_conv1)\n",
    "        disc_conv1 = LeakyReLU()(disc_conv1)\n",
    "\n",
    "        #32x32\n",
    "        disc_conv1 = Conv2D(128, (3, 3), padding='same', strides=2)(disc_conv1)\n",
    "        disc_conv1 = BatchNormalization()(disc_conv1)\n",
    "        disc_conv1 = LeakyReLU()(disc_conv1)\n",
    "\n",
    "        #16x16\n",
    "        disc_conv1 = Conv2D(256, (3, 3), padding='same', strides=2)(disc_conv1)\n",
    "        disc_conv1 = BatchNormalization()(disc_conv1)\n",
    "        disc_conv1 = LeakyReLU()(disc_conv1)\n",
    "        \n",
    "        #8x8\n",
    "        disc_conv1 = Conv2D(256, (3, 3), padding='same', strides=2)(disc_conv1)\n",
    "        disc_conv1 = BatchNormalization()(disc_conv1)\n",
    "        disc_conv1 = LeakyReLU()(disc_conv1)\n",
    "        \n",
    "        #4x4\n",
    "        disc_conv1 = Conv2D(512, (3, 3), padding='same', strides=2)(disc_conv1)\n",
    "        disc_conv1 = BatchNormalization()(disc_conv1)\n",
    "        disc_conv1 = LeakyReLU()(disc_conv1)\n",
    "\n",
    "\n",
    "        final = Dropout(.4)(disc_conv1)\n",
    "        final = Flatten()(final)\n",
    "        final = Dense(1)(final)\n",
    "        final = Activation('sigmoid')(final)\n",
    "        \n",
    "        model = Model(inputs = [d_input_l, d_input_lab], outputs = final)\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def train(self, X_train_L, X_train_LAB, epochs):\n",
    "        \n",
    "        #Training loop for GAN.\n",
    "        #Inputs: X_train L channel, X_train AB channels, number of epochs.\n",
    "        #Outputs: Models are saved and loss/acc plots saved.\n",
    "\n",
    "        g_losses = []\n",
    "        d_losses = []\n",
    "        d_acc = []\n",
    "        X_train = X_train_L\n",
    "        n = len(X_train)\n",
    "        # real pictures label - 1, fake pictures label - 0\n",
    "        y_train_fake = np.zeros([n,1])\n",
    "        y_train_fake_s = np.full([n,1], 0.0)\n",
    "        y_train_real_s = np.full([n,1], 0.9)\n",
    "        y_train_real = np.ones([n,1])\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            print(\"Epochs:\")\n",
    "            print(e)\n",
    "            \n",
    "           #Generate images\n",
    "            generated_images = self.generator.predict(X_train, verbose=1)\n",
    "\n",
    "            #Train Discriminator - first real images, next fake\n",
    "            d_loss  = self.discriminator.fit(x=[X_train_L, X_train_LAB], y=y_train_real_s,  batch_size=8, epochs=1, shuffle=True)\n",
    "            #noisy labels\n",
    "            if e % 3 == 2:\n",
    "                noise = np.random.rand(n,128,128,3) * 2 -1\n",
    "                d_loss = self.discriminator.fit(x=[X_train_L, noise], y=y_train_fake, batch_size=8, epochs=1)\n",
    "            d_loss = self.discriminator.fit(x=[X_train_L,generated_images], y=y_train_fake, batch_size=8, epochs=1, shuffle=True)\n",
    "            d_losses.append(d_loss.history['loss'][-1])\n",
    "            d_acc.append(d_loss.history['acc'][-1])\n",
    "            print('d_loss:', d_loss.history['loss'][-1])\n",
    "\n",
    "            #train GAN on grayscaled images , set output class to colorized\n",
    "            g_loss = self.gan.fit(x=X_train, y=y_train_real, batch_size=8, epochs=1)\n",
    "\n",
    "            #Record Losses/Acc\n",
    "            g_losses.append(g_loss.history['loss'][-1])\n",
    "            print('Generator Loss: ', g_loss.history['loss'][-1])\n",
    "            disc_acc = d_loss.history['acc'][-1]\n",
    "            print(\"Discriminator Accuracy: \", disc_acc)\n",
    "\n",
    "            if e % 5 == 4:\n",
    "                print(e + 1,\"batches done\")\n",
    "            if e % 250 == 0:\n",
    "                self.plot_losses(g_losses,'Generative Loss UNet Semi', e)\n",
    "                self.plot_losses(d_acc, 'Discriminative Accuracy Unet Semi',e)\n",
    "                self.generator.save('../unet_model_semi_batch_' + str(e)+'.h5')\n",
    "                self.discriminator.save('../u_disc_model_semi_batch_' + str(e)+'.h5')\n",
    "\n",
    "        #save outputs\n",
    "        self.plot_losses(g_losses,'Generative Loss', epochs)\n",
    "        self.plot_losses(d_acc, 'Discriminative Accuracy',epochs)\n",
    "        self.generator.save('../unet_model_full_batch_' + str(epochs)+'.h5')\n",
    "        self.discriminator.save('../u_disc_model_full_batch_' + str(epochs)+'.h5')\n",
    "\n",
    "    def plot_losses(self, metric, label, epochs):\n",
    "        \n",
    "        #Plot the loss/acc of the generator/discriminator.\n",
    "        #Inputs: metric, label of graph, number of epochs (for file name)\n",
    "        \n",
    "        plt.plot(metric, label=label)\n",
    "        plt.title('GAN Accuracy and Loss Over ' + str(epochs) + ' Epochs')\n",
    "        plt.savefig('../plot_' + str(epochs) + '_epochs.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
