{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colorization of panchromatic space images with Generative Adversarial Network\n",
    "\n",
    "Author: Patrycja Cieplicka\n",
    "\n",
    "Date: 12 Jan 2020\n",
    "\n",
    "Implementation of class Generative Adversarial Network for main model colorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.packages import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize random numbers generator \n",
    "np.random.seed(1)\n",
    "set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN_ab():\n",
    "    def __init__(self, lr_gen, lr_disc):\n",
    "        \n",
    "        #input shape for generator\n",
    "        self.g_input_shape = (128,128,1)\n",
    "        #output shape for generator\n",
    "        self.g_output_shape = (128,128,2)\n",
    "        \n",
    "        #Compiling generator\n",
    "        print(\"Generator architecture\")\n",
    "        self.generator = self.build_generator()\n",
    "        opti = Adam(lr=lr_gen)\n",
    "        self.generator.compile(loss='binary_crossentropy', optimizer=opti)\n",
    "        print(self.generator.summary())\n",
    "        \n",
    "        #Compiling discriminator\n",
    "        print('Discriminator architecture')\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        opti = Adam(lr=lr_disc)\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=opti, metrics=['accuracy'])\n",
    "        print(self.discriminator.summary())\n",
    "\n",
    "        #Initialize GAN\n",
    "        gan_input = Input(shape=self.g_input_shape)\n",
    "        img_color = self.generator(gan_input)\n",
    "        self.discriminator.trainable = False\n",
    "        real_or_fake = self.discriminator([gan_input, img_color])\n",
    "        self.gan = Model(inputs = gan_input, outputs = real_or_fake)\n",
    "        \n",
    "        #Compiling GAN\n",
    "        opti = Adam(lr=lr_gen)\n",
    "        self.gan.compile(loss='binary_crossentropy', optimizer=opti)\n",
    "        print('\\n')\n",
    "        print('GAN summary...')\n",
    "        print(self.gan.summary())\n",
    "\n",
    "    def build_generator(self):\n",
    "        #Generator architecture\n",
    "        \n",
    "        g_input = Input(shape=self.g_input_shape)\n",
    "        \n",
    "        #128 x 128\n",
    "        conv1 = Conv2D(64, (3, 3), padding='same', strides=2)(g_input)\n",
    "        conv1 = BatchNormalization()(conv1)\n",
    "        conv1 = Activation('relu')(conv1)\n",
    "        \n",
    "        #64 x 64\n",
    "        conv2 = Conv2D(128, (3, 3), padding='same', strides=1)(conv1)\n",
    "        conv2 = BatchNormalization()(conv2)\n",
    "        conv2 = Activation('relu')(conv2)\n",
    "\n",
    "        conv3 = Conv2D(128, (3, 3), padding='same', strides=2)(conv2)\n",
    "        conv3 = BatchNormalization()(conv3)\n",
    "        conv3 = Activation('relu')(conv3)\n",
    "\n",
    "        #32 x 32\n",
    "        conv4 = Conv2D(256, (3, 3), padding='same', strides=1)(conv3)\n",
    "        conv4 = BatchNormalization()(conv4)\n",
    "        conv4 = Activation('relu')(conv4)\n",
    "        \n",
    "        conv5 = Conv2D(256, (3, 3), padding='same', strides=2)(conv4)\n",
    "        conv5 = BatchNormalization()(conv5)\n",
    "        conv5 = Activation('relu')(conv5)\n",
    "\n",
    "        #16 x16\n",
    "        conv6 = Conv2D(512, (3, 3), padding='same', strides=1)(conv5)\n",
    "        conv6 = BatchNormalization()(conv5)\n",
    "        conv6 = Activation('relu')(conv5)\n",
    "\n",
    "        conv7 = Conv2D(512, (3, 3), padding='same', strides=2)(conv6)\n",
    "        conv7 = BatchNormalization()(conv7)\n",
    "        conv7 = Activation('relu')(conv7)\n",
    "        \n",
    "        \n",
    "        conv8 = UpSampling2D(size=(2, 2))(conv7)\n",
    "        conv8 = Conv2D(512, (3, 3), padding='same')(conv8)\n",
    "        conv8 = BatchNormalization()(conv8)\n",
    "        conv8 = Activation('relu')(conv8)\n",
    "        conv8 = Concatenate(axis=-1)([conv8,conv6])\n",
    "\n",
    "        #16 x 16\n",
    "        conv9 = Conv2D(512, (3, 3), padding='same')(conv8)\n",
    "        conv9 = BatchNormalization()(conv9)\n",
    "        conv9 = Activation('relu')(conv9)\n",
    "\n",
    "        conv10 = UpSampling2D(size=(2, 2))(conv9)\n",
    "        conv10 = Conv2D(256, (3, 3), padding='same')(conv10)\n",
    "        conv10 = BatchNormalization()(conv10)\n",
    "        conv10 = Activation('relu')(conv10)\n",
    "        conv10 = Concatenate(axis=-1)([conv10,conv4])\n",
    "        \n",
    "        #32 x 32\n",
    "        conv11 = Conv2D(256, (3, 3), padding='same')(conv10)\n",
    "        conv11 = BatchNormalization()(conv11)\n",
    "        conv11 = Activation('relu')(conv11)\n",
    "\n",
    "        conv12 = UpSampling2D(size=(2, 2))(conv11)\n",
    "        conv12 = Conv2D(128, (3,3), padding='same')(conv12)\n",
    "        conv12 = BatchNormalization()(conv12)\n",
    "        conv12 = Activation('relu')(conv12)\n",
    "        conv12 = Concatenate(axis=-1)([conv12,conv2])\n",
    "        \n",
    "        #64 x 64\n",
    "        conv13 = Conv2D(128, (3, 3), padding='same')(conv12)\n",
    "        conv13 = BatchNormalization()(conv13)\n",
    "        conv13 = Activation('relu')(conv13)\n",
    "        \n",
    "        conv14 = UpSampling2D(size=(2, 2))(conv13)\n",
    "        conv14 = Conv2D(64, (3,3), padding='same')(conv14)\n",
    "        conv14 = BatchNormalization()(conv14)\n",
    "        conv14 = Activation('relu')(conv14)\n",
    "        \n",
    "        #128 x 128\n",
    "        conv15 = Conv2D(2, (3, 3), padding='same')(conv14)\n",
    "        conv15 = Activation('tanh')(conv15)\n",
    "\n",
    "        model = Model(inputs=g_input,outputs=conv15)\n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        #Dicriminator architecture\n",
    "        \n",
    "        d_input_l = Input(shape=self.g_input_shape)\n",
    "        d_input_ab = Input(shape=self.g_output_shape)\n",
    "        \n",
    "        #128 x128\n",
    "        disc_conv1 = concatenate([d_input_l, d_input_ab], axis=3) \n",
    "        disc_conv1 = Conv2D(32, (3, 3), padding='same', strides=1)(disc_conv1)\n",
    "        disc_conv1 = BatchNormalization()(disc_conv1)\n",
    "        disc_conv1 = LeakyReLU()(disc_conv1)\n",
    "\n",
    "        disc_conv2 = Conv2D(64, (3, 3), padding='same', strides=2)(disc_conv1)\n",
    "        disc_conv2 = BatchNormalization()(disc_conv2)\n",
    "        disc_conv2 = LeakyReLU()(disc_conv2)\n",
    "\n",
    "        #64x64\n",
    "        disc_conv3 = Conv2D(128, (3, 3), padding='same', strides=2)(disc_conv2)\n",
    "        disc_conv3 = BatchNormalization()(disc_conv3)\n",
    "        disc_conv3 = LeakyReLU()(disc_conv3)\n",
    "\n",
    "        #32x32\n",
    "        disc_conv4 = Conv2D(128, (3, 3), padding='same', strides=2)(disc_conv3)\n",
    "        disc_conv4 = BatchNormalization()(disc_conv4)\n",
    "        disc_conv4 = LeakyReLU()(disc_conv4)\n",
    "\n",
    "        #16x16\n",
    "        disc_conv5 = Conv2D(256, (3, 3), padding='same', strides=2)(disc_conv4)\n",
    "        disc_conv5 = BatchNormalization()(disc_conv5)\n",
    "        disc_conv5 = LeakyReLU()(disc_conv5)\n",
    "        \n",
    "        #8x8\n",
    "        disc_conv6 = Conv2D(256, (3, 3), padding='same', strides=2)(disc_conv5)\n",
    "        disc_conv6 = BatchNormalization()(disc_conv6)\n",
    "        disc_conv6 = LeakyReLU()(disc_conv6)\n",
    "        \n",
    "        #4x4\n",
    "        disc_conv7 = Conv2D(512, (3, 3), padding='same', strides=2)(disc_conv6)\n",
    "        disc_conv7 = BatchNormalization()(disc_conv7)\n",
    "        disc_conv7 = LeakyReLU()(disc_conv7)\n",
    "\n",
    "        final = Dropout(.4)(disc_conv7)\n",
    "        final = Flatten()(final)\n",
    "        final = Dense(1)(final)\n",
    "        final = Activation('sigmoid')(final)\n",
    "        \n",
    "        model = Model(inputs = [d_input_l, d_input_ab], outputs = final)\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def train(self, X_train_L, X_train_AB, epochs, label):\n",
    "        \n",
    "        #Training loop for GAN.\n",
    "        #Inputs: X_train (L channel), X_train_AB (ab channels), epochs (number of epochs), \n",
    "        #label (label for true images)\n",
    "        #Outputs: No outputs, models are saved to file\n",
    "\n",
    "        g_losses = [] #genrator loss\n",
    "        d_losses = [] #discriminator loss\n",
    "        d_acc = [] #discriminator accurency\n",
    "        \n",
    "        X_train = X_train_L\n",
    "        \n",
    "        n = len(X_train) #number of train images\n",
    "\n",
    "        y_train_fake = np.zeros([n,1]) # fake pictures label, always 0\n",
    "        y_train_real = np.full([n,1], label) # real pictures label\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            print(\"Epochs:\")\n",
    "            print(e)\n",
    "            \n",
    "            # generator generates images\n",
    "            generated_images = self.generator.predict(X_train, verbose=1) \n",
    "\n",
    "            #train discriminator\n",
    "            #first - train on real images\n",
    "            d_loss  = self.discriminator.fit(x=[X_train_L, X_train_AB], y=y_train_real,  batch_size=8, \n",
    "                                             epochs=1, shuffle=True)\n",
    "            #second - every third epochs noisy labels\n",
    "            if e % 3 == 2:\n",
    "                noise = np.random.rand(n,128,128,2) * 2 -1\n",
    "                d_loss = self.discriminator.fit(x=[X_train_L, noise], y=y_train_fake, \n",
    "                                                batch_size=8, epochs=1)\n",
    "            #third - train on generated image\n",
    "            d_loss = self.discriminator.fit(x=[X_train_L,generated_images], y=y_train_fake, batch_size=8, \n",
    "                                            epochs=1, shuffle=True)\n",
    "            #save history\n",
    "            d_losses.append(d_loss.history['loss'][-1])\n",
    "            d_acc.append(d_loss.history['acc'][-1])\n",
    "            print('d_loss:', d_loss.history['loss'][-1])\n",
    "\n",
    "            #train generator\n",
    "            #train GAN on panachromatic images, set output class to colorized\n",
    "            g_loss = self.gan.fit(x=X_train, y=y_train_real, batch_size=8, epochs=1)\n",
    "\n",
    "            #save history\n",
    "            g_losses.append(g_loss.history['loss'][-1])\n",
    "            print('Generator Loss: ', g_loss.history['loss'][-1])\n",
    "            disc_acc = d_loss.history['acc'][-1]\n",
    "            print(\"Discriminator Accuracy: \", disc_acc)\n",
    "\n",
    "            if e % 5 == 4:\n",
    "                print(e + 1,\"batches done\")\n",
    "            \n",
    "            #save model every 250th epoch\n",
    "            if e % 250 == 0:\n",
    "                self.plot_losses(g_losses,'Generative Loss', e)\n",
    "                self.plot_losses(d_acc, 'Discriminative Accuracy',e)\n",
    "                self.generator.save('../unet_model_semi_batch_' + str(e)+'.h5')\n",
    "                self.discriminator.save('../u_disc_model_semi_batch_' + str(e)+'.h5')\n",
    "                \n",
    "        #save final model\n",
    "        self.plot_losses(g_losses,'Generative Loss', epochs)\n",
    "        self.plot_losses(d_acc, 'Discriminative Accuracy', epochs)\n",
    "        self.generator.save('../unet_model_ab_full_batch_' + str(epochs)+'.h5')\n",
    "        self.discriminator.save('../u_disc_model_ab_full_batch_' + str(epochs)+'.h5')\n",
    "\n",
    "    def plot_losses(self, metric, label, epochs):\n",
    "        \n",
    "        #Plot and save the loss of the generator and accurancy of the discriminator\n",
    "        #Inputs: metric, label of graph, number of epochs\n",
    "        \n",
    "        plt.plot(metric, label=label)\n",
    "        plt.title('GAN Accuracy and Loss Over ' + str(epochs) + ' Epochs')\n",
    "        plt.savefig('../plot_' + str(epochs) + '_epochs.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
